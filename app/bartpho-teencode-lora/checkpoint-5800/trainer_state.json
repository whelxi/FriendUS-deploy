{
  "best_global_step": 5200,
  "best_metric": 75.5888902287065,
  "best_model_checkpoint": "./bartpho-teencode-lora\\checkpoint-5200",
  "epoch": 3.4482758620689653,
  "eval_steps": 200,
  "global_step": 5800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.029726516052318668,
      "grad_norm": 1.7314116954803467,
      "learning_rate": 0.00029825208085612365,
      "loss": 3.1215,
      "step": 50
    },
    {
      "epoch": 0.059453032104637336,
      "grad_norm": 1.5226783752441406,
      "learning_rate": 0.0002964684898929845,
      "loss": 2.1176,
      "step": 100
    },
    {
      "epoch": 0.089179548156956,
      "grad_norm": 1.3707932233810425,
      "learning_rate": 0.00029468489892984536,
      "loss": 2.0217,
      "step": 150
    },
    {
      "epoch": 0.11890606420927467,
      "grad_norm": 1.418933629989624,
      "learning_rate": 0.00029290130796670626,
      "loss": 1.8608,
      "step": 200
    },
    {
      "epoch": 0.11890606420927467,
      "eval_bleu": 44.03582514520253,
      "eval_loss": 1.4620118141174316,
      "eval_runtime": 148.7308,
      "eval_samples_per_second": 1.345,
      "eval_steps_per_second": 0.672,
      "step": 200
    },
    {
      "epoch": 0.14863258026159334,
      "grad_norm": 1.425356149673462,
      "learning_rate": 0.00029111771700356717,
      "loss": 1.8207,
      "step": 250
    },
    {
      "epoch": 0.178359096313912,
      "grad_norm": 1.2061432600021362,
      "learning_rate": 0.000289334126040428,
      "loss": 1.7589,
      "step": 300
    },
    {
      "epoch": 0.2080856123662307,
      "grad_norm": 1.3687859773635864,
      "learning_rate": 0.0002875505350772889,
      "loss": 1.7165,
      "step": 350
    },
    {
      "epoch": 0.23781212841854935,
      "grad_norm": 1.5891684293746948,
      "learning_rate": 0.00028576694411414983,
      "loss": 1.6627,
      "step": 400
    },
    {
      "epoch": 0.23781212841854935,
      "eval_bleu": 47.011841422310326,
      "eval_loss": 1.2739386558532715,
      "eval_runtime": 87.4788,
      "eval_samples_per_second": 2.286,
      "eval_steps_per_second": 1.143,
      "step": 400
    },
    {
      "epoch": 0.267538644470868,
      "grad_norm": 1.3989083766937256,
      "learning_rate": 0.0002839833531510107,
      "loss": 1.5725,
      "step": 450
    },
    {
      "epoch": 0.2972651605231867,
      "grad_norm": 1.279672384262085,
      "learning_rate": 0.00028219976218787153,
      "loss": 1.556,
      "step": 500
    },
    {
      "epoch": 0.3269916765755054,
      "grad_norm": 1.1268773078918457,
      "learning_rate": 0.00028041617122473244,
      "loss": 1.5099,
      "step": 550
    },
    {
      "epoch": 0.356718192627824,
      "grad_norm": 1.1129140853881836,
      "learning_rate": 0.00027863258026159334,
      "loss": 1.4127,
      "step": 600
    },
    {
      "epoch": 0.356718192627824,
      "eval_bleu": 49.618540611409706,
      "eval_loss": 1.1143388748168945,
      "eval_runtime": 94.2659,
      "eval_samples_per_second": 2.122,
      "eval_steps_per_second": 1.061,
      "step": 600
    },
    {
      "epoch": 0.3864447086801427,
      "grad_norm": 1.3281075954437256,
      "learning_rate": 0.0002768489892984542,
      "loss": 1.3828,
      "step": 650
    },
    {
      "epoch": 0.4161712247324614,
      "grad_norm": 1.5321108102798462,
      "learning_rate": 0.0002750653983353151,
      "loss": 1.4395,
      "step": 700
    },
    {
      "epoch": 0.44589774078478,
      "grad_norm": 1.659807562828064,
      "learning_rate": 0.00027328180737217595,
      "loss": 1.3757,
      "step": 750
    },
    {
      "epoch": 0.4756242568370987,
      "grad_norm": 1.3085098266601562,
      "learning_rate": 0.0002714982164090368,
      "loss": 1.3472,
      "step": 800
    },
    {
      "epoch": 0.4756242568370987,
      "eval_bleu": 52.878859777843275,
      "eval_loss": 1.0035375356674194,
      "eval_runtime": 93.6822,
      "eval_samples_per_second": 2.135,
      "eval_steps_per_second": 1.067,
      "step": 800
    },
    {
      "epoch": 0.5053507728894173,
      "grad_norm": 1.4492504596710205,
      "learning_rate": 0.0002697146254458977,
      "loss": 1.2626,
      "step": 850
    },
    {
      "epoch": 0.535077288941736,
      "grad_norm": 1.2408908605575562,
      "learning_rate": 0.0002679310344827586,
      "loss": 1.2527,
      "step": 900
    },
    {
      "epoch": 0.5648038049940547,
      "grad_norm": 1.3119378089904785,
      "learning_rate": 0.00026614744351961947,
      "loss": 1.1834,
      "step": 950
    },
    {
      "epoch": 0.5945303210463734,
      "grad_norm": 2.056898355484009,
      "learning_rate": 0.00026436385255648037,
      "loss": 1.2273,
      "step": 1000
    },
    {
      "epoch": 0.5945303210463734,
      "eval_bleu": 55.42752809219775,
      "eval_loss": 0.858483076095581,
      "eval_runtime": 91.4551,
      "eval_samples_per_second": 2.187,
      "eval_steps_per_second": 1.093,
      "step": 1000
    },
    {
      "epoch": 0.6242568370986921,
      "grad_norm": 1.720349669456482,
      "learning_rate": 0.0002625802615933412,
      "loss": 1.1878,
      "step": 1050
    },
    {
      "epoch": 0.6539833531510107,
      "grad_norm": 1.8626189231872559,
      "learning_rate": 0.00026079667063020213,
      "loss": 1.1693,
      "step": 1100
    },
    {
      "epoch": 0.6837098692033293,
      "grad_norm": 1.3925671577453613,
      "learning_rate": 0.000259013079667063,
      "loss": 1.0971,
      "step": 1150
    },
    {
      "epoch": 0.713436385255648,
      "grad_norm": 1.340253472328186,
      "learning_rate": 0.0002572294887039239,
      "loss": 1.1312,
      "step": 1200
    },
    {
      "epoch": 0.713436385255648,
      "eval_bleu": 55.84502244448221,
      "eval_loss": 0.8363533020019531,
      "eval_runtime": 90.2741,
      "eval_samples_per_second": 2.215,
      "eval_steps_per_second": 1.108,
      "step": 1200
    },
    {
      "epoch": 0.7431629013079667,
      "grad_norm": 1.3650306463241577,
      "learning_rate": 0.0002554458977407848,
      "loss": 1.1011,
      "step": 1250
    },
    {
      "epoch": 0.7728894173602854,
      "grad_norm": 3.0823161602020264,
      "learning_rate": 0.00025366230677764564,
      "loss": 1.0435,
      "step": 1300
    },
    {
      "epoch": 0.8026159334126041,
      "grad_norm": 1.3935894966125488,
      "learning_rate": 0.0002518787158145065,
      "loss": 1.054,
      "step": 1350
    },
    {
      "epoch": 0.8323424494649228,
      "grad_norm": 1.5700933933258057,
      "learning_rate": 0.0002500951248513674,
      "loss": 1.0325,
      "step": 1400
    },
    {
      "epoch": 0.8323424494649228,
      "eval_bleu": 60.07753075740664,
      "eval_loss": 0.7626646161079407,
      "eval_runtime": 89.6347,
      "eval_samples_per_second": 2.231,
      "eval_steps_per_second": 1.116,
      "step": 1400
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 12.911139488220215,
      "learning_rate": 0.00024831153388822825,
      "loss": 0.9835,
      "step": 1450
    },
    {
      "epoch": 0.89179548156956,
      "grad_norm": 1.6432422399520874,
      "learning_rate": 0.00024652794292508916,
      "loss": 0.9913,
      "step": 1500
    },
    {
      "epoch": 0.9215219976218787,
      "grad_norm": 1.3775008916854858,
      "learning_rate": 0.00024474435196195006,
      "loss": 1.0365,
      "step": 1550
    },
    {
      "epoch": 0.9512485136741974,
      "grad_norm": 1.863409399986267,
      "learning_rate": 0.00024296076099881094,
      "loss": 1.006,
      "step": 1600
    },
    {
      "epoch": 0.9512485136741974,
      "eval_bleu": 62.96434884083684,
      "eval_loss": 0.713876485824585,
      "eval_runtime": 90.3564,
      "eval_samples_per_second": 2.213,
      "eval_steps_per_second": 1.107,
      "step": 1600
    },
    {
      "epoch": 0.9809750297265161,
      "grad_norm": 1.4761472940444946,
      "learning_rate": 0.0002411771700356718,
      "loss": 0.9904,
      "step": 1650
    },
    {
      "epoch": 1.0107015457788346,
      "grad_norm": 1.3275870084762573,
      "learning_rate": 0.00023939357907253267,
      "loss": 0.8935,
      "step": 1700
    },
    {
      "epoch": 1.0404280618311534,
      "grad_norm": 1.198551893234253,
      "learning_rate": 0.00023760998810939355,
      "loss": 0.9281,
      "step": 1750
    },
    {
      "epoch": 1.070154577883472,
      "grad_norm": 1.3809797763824463,
      "learning_rate": 0.00023582639714625443,
      "loss": 0.8942,
      "step": 1800
    },
    {
      "epoch": 1.070154577883472,
      "eval_bleu": 64.0209648523449,
      "eval_loss": 0.712898850440979,
      "eval_runtime": 93.0221,
      "eval_samples_per_second": 2.15,
      "eval_steps_per_second": 1.075,
      "step": 1800
    },
    {
      "epoch": 1.0998810939357908,
      "grad_norm": 1.8821600675582886,
      "learning_rate": 0.00023404280618311533,
      "loss": 0.8757,
      "step": 1850
    },
    {
      "epoch": 1.1296076099881094,
      "grad_norm": 1.4681940078735352,
      "learning_rate": 0.0002322592152199762,
      "loss": 0.9154,
      "step": 1900
    },
    {
      "epoch": 1.1593341260404282,
      "grad_norm": 2.0301711559295654,
      "learning_rate": 0.00023047562425683706,
      "loss": 0.9029,
      "step": 1950
    },
    {
      "epoch": 1.1890606420927468,
      "grad_norm": 1.3054879903793335,
      "learning_rate": 0.00022869203329369794,
      "loss": 0.8233,
      "step": 2000
    },
    {
      "epoch": 1.1890606420927468,
      "eval_bleu": 65.61174081425338,
      "eval_loss": 0.6387425065040588,
      "eval_runtime": 96.4251,
      "eval_samples_per_second": 2.074,
      "eval_steps_per_second": 1.037,
      "step": 2000
    },
    {
      "epoch": 1.2187871581450653,
      "grad_norm": 1.1852953433990479,
      "learning_rate": 0.00022690844233055885,
      "loss": 0.8762,
      "step": 2050
    },
    {
      "epoch": 1.2485136741973841,
      "grad_norm": 1.0986981391906738,
      "learning_rate": 0.00022512485136741973,
      "loss": 0.8229,
      "step": 2100
    },
    {
      "epoch": 1.2782401902497027,
      "grad_norm": 1.4805817604064941,
      "learning_rate": 0.0002233412604042806,
      "loss": 0.8638,
      "step": 2150
    },
    {
      "epoch": 1.3079667063020213,
      "grad_norm": 1.8175718784332275,
      "learning_rate": 0.00022155766944114148,
      "loss": 0.8232,
      "step": 2200
    },
    {
      "epoch": 1.3079667063020213,
      "eval_bleu": 67.58669800782995,
      "eval_loss": 0.5859655141830444,
      "eval_runtime": 95.8471,
      "eval_samples_per_second": 2.087,
      "eval_steps_per_second": 1.043,
      "step": 2200
    },
    {
      "epoch": 1.33769322235434,
      "grad_norm": 2.1081137657165527,
      "learning_rate": 0.00021977407847800234,
      "loss": 0.8903,
      "step": 2250
    },
    {
      "epoch": 1.3674197384066589,
      "grad_norm": 1.477962613105774,
      "learning_rate": 0.00021799048751486324,
      "loss": 0.779,
      "step": 2300
    },
    {
      "epoch": 1.3971462544589774,
      "grad_norm": 1.042934536933899,
      "learning_rate": 0.00021620689655172412,
      "loss": 0.8016,
      "step": 2350
    },
    {
      "epoch": 1.426872770511296,
      "grad_norm": 1.4094754457473755,
      "learning_rate": 0.000214423305588585,
      "loss": 0.8505,
      "step": 2400
    },
    {
      "epoch": 1.426872770511296,
      "eval_bleu": 68.88635240705766,
      "eval_loss": 0.5586898326873779,
      "eval_runtime": 95.4865,
      "eval_samples_per_second": 2.095,
      "eval_steps_per_second": 1.047,
      "step": 2400
    },
    {
      "epoch": 1.4565992865636148,
      "grad_norm": 1.3586153984069824,
      "learning_rate": 0.00021263971462544588,
      "loss": 0.7973,
      "step": 2450
    },
    {
      "epoch": 1.4863258026159334,
      "grad_norm": 1.8026247024536133,
      "learning_rate": 0.00021085612366230678,
      "loss": 0.8129,
      "step": 2500
    },
    {
      "epoch": 1.516052318668252,
      "grad_norm": 1.2828670740127563,
      "learning_rate": 0.00020907253269916763,
      "loss": 0.7907,
      "step": 2550
    },
    {
      "epoch": 1.5457788347205708,
      "grad_norm": 1.7560440301895142,
      "learning_rate": 0.0002072889417360285,
      "loss": 0.7811,
      "step": 2600
    },
    {
      "epoch": 1.5457788347205708,
      "eval_bleu": 68.5648662490051,
      "eval_loss": 0.6041936278343201,
      "eval_runtime": 88.4976,
      "eval_samples_per_second": 2.26,
      "eval_steps_per_second": 1.13,
      "step": 2600
    },
    {
      "epoch": 1.5755053507728896,
      "grad_norm": 1.3582018613815308,
      "learning_rate": 0.0002055053507728894,
      "loss": 0.814,
      "step": 2650
    },
    {
      "epoch": 1.6052318668252081,
      "grad_norm": 1.5355420112609863,
      "learning_rate": 0.0002037217598097503,
      "loss": 0.8089,
      "step": 2700
    },
    {
      "epoch": 1.6349583828775267,
      "grad_norm": 1.1093122959136963,
      "learning_rate": 0.00020193816884661118,
      "loss": 0.7929,
      "step": 2750
    },
    {
      "epoch": 1.6646848989298455,
      "grad_norm": 1.2943648099899292,
      "learning_rate": 0.00020015457788347205,
      "loss": 0.7664,
      "step": 2800
    },
    {
      "epoch": 1.6646848989298455,
      "eval_bleu": 70.04754415539078,
      "eval_loss": 0.5635272860527039,
      "eval_runtime": 89.8601,
      "eval_samples_per_second": 2.226,
      "eval_steps_per_second": 1.113,
      "step": 2800
    },
    {
      "epoch": 1.694411414982164,
      "grad_norm": 1.2385449409484863,
      "learning_rate": 0.0001983709869203329,
      "loss": 0.7425,
      "step": 2850
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 1.6005803346633911,
      "learning_rate": 0.00019658739595719378,
      "loss": 0.7699,
      "step": 2900
    },
    {
      "epoch": 1.7538644470868014,
      "grad_norm": 1.5225259065628052,
      "learning_rate": 0.0001948038049940547,
      "loss": 0.7685,
      "step": 2950
    },
    {
      "epoch": 1.7835909631391202,
      "grad_norm": 1.9323498010635376,
      "learning_rate": 0.00019302021403091557,
      "loss": 0.7437,
      "step": 3000
    },
    {
      "epoch": 1.7835909631391202,
      "eval_bleu": 70.93539199028254,
      "eval_loss": 0.5694327354431152,
      "eval_runtime": 88.8869,
      "eval_samples_per_second": 2.25,
      "eval_steps_per_second": 1.125,
      "step": 3000
    },
    {
      "epoch": 1.8133174791914386,
      "grad_norm": 1.2066607475280762,
      "learning_rate": 0.00019123662306777645,
      "loss": 0.7526,
      "step": 3050
    },
    {
      "epoch": 1.8430439952437574,
      "grad_norm": 1.205094814300537,
      "learning_rate": 0.0001894530321046373,
      "loss": 0.7442,
      "step": 3100
    },
    {
      "epoch": 1.8727705112960762,
      "grad_norm": 1.2524511814117432,
      "learning_rate": 0.00018766944114149818,
      "loss": 0.7507,
      "step": 3150
    },
    {
      "epoch": 1.9024970273483948,
      "grad_norm": 1.4446825981140137,
      "learning_rate": 0.00018588585017835908,
      "loss": 0.7492,
      "step": 3200
    },
    {
      "epoch": 1.9024970273483948,
      "eval_bleu": 70.84654629889916,
      "eval_loss": 0.5384843945503235,
      "eval_runtime": 86.3941,
      "eval_samples_per_second": 2.315,
      "eval_steps_per_second": 1.157,
      "step": 3200
    },
    {
      "epoch": 1.9322235434007133,
      "grad_norm": 1.7989513874053955,
      "learning_rate": 0.00018410225921521996,
      "loss": 0.7025,
      "step": 3250
    },
    {
      "epoch": 1.9619500594530321,
      "grad_norm": 1.630579948425293,
      "learning_rate": 0.00018231866825208084,
      "loss": 0.6981,
      "step": 3300
    },
    {
      "epoch": 1.991676575505351,
      "grad_norm": 1.0682851076126099,
      "learning_rate": 0.00018053507728894175,
      "loss": 0.6948,
      "step": 3350
    },
    {
      "epoch": 2.0214030915576693,
      "grad_norm": 1.3196914196014404,
      "learning_rate": 0.0001787514863258026,
      "loss": 0.6687,
      "step": 3400
    },
    {
      "epoch": 2.0214030915576693,
      "eval_bleu": 72.23793222548078,
      "eval_loss": 0.5196458697319031,
      "eval_runtime": 91.5163,
      "eval_samples_per_second": 2.185,
      "eval_steps_per_second": 1.093,
      "step": 3400
    },
    {
      "epoch": 2.051129607609988,
      "grad_norm": 1.3535962104797363,
      "learning_rate": 0.00017696789536266348,
      "loss": 0.6909,
      "step": 3450
    },
    {
      "epoch": 2.080856123662307,
      "grad_norm": 0.9855783581733704,
      "learning_rate": 0.00017518430439952435,
      "loss": 0.6726,
      "step": 3500
    },
    {
      "epoch": 2.1105826397146252,
      "grad_norm": 1.2201292514801025,
      "learning_rate": 0.00017340071343638523,
      "loss": 0.707,
      "step": 3550
    },
    {
      "epoch": 2.140309155766944,
      "grad_norm": 1.6546186208724976,
      "learning_rate": 0.00017161712247324614,
      "loss": 0.6956,
      "step": 3600
    },
    {
      "epoch": 2.140309155766944,
      "eval_bleu": 71.47550294671491,
      "eval_loss": 0.530174732208252,
      "eval_runtime": 85.4464,
      "eval_samples_per_second": 2.341,
      "eval_steps_per_second": 1.17,
      "step": 3600
    },
    {
      "epoch": 2.170035671819263,
      "grad_norm": 1.4041023254394531,
      "learning_rate": 0.00016983353151010702,
      "loss": 0.6583,
      "step": 3650
    },
    {
      "epoch": 2.1997621878715816,
      "grad_norm": 1.6646064519882202,
      "learning_rate": 0.00016804994054696787,
      "loss": 0.6586,
      "step": 3700
    },
    {
      "epoch": 2.2294887039239,
      "grad_norm": 1.5838117599487305,
      "learning_rate": 0.00016626634958382875,
      "loss": 0.7084,
      "step": 3750
    },
    {
      "epoch": 2.2592152199762188,
      "grad_norm": 1.1882145404815674,
      "learning_rate": 0.00016448275862068962,
      "loss": 0.6429,
      "step": 3800
    },
    {
      "epoch": 2.2592152199762188,
      "eval_bleu": 72.28125881064291,
      "eval_loss": 0.4952924847602844,
      "eval_runtime": 94.1078,
      "eval_samples_per_second": 2.125,
      "eval_steps_per_second": 1.063,
      "step": 3800
    },
    {
      "epoch": 2.2889417360285376,
      "grad_norm": 1.4089298248291016,
      "learning_rate": 0.00016269916765755053,
      "loss": 0.6998,
      "step": 3850
    },
    {
      "epoch": 2.3186682520808564,
      "grad_norm": 1.1555991172790527,
      "learning_rate": 0.0001609155766944114,
      "loss": 0.6431,
      "step": 3900
    },
    {
      "epoch": 2.3483947681331747,
      "grad_norm": 1.1336184740066528,
      "learning_rate": 0.0001591319857312723,
      "loss": 0.643,
      "step": 3950
    },
    {
      "epoch": 2.3781212841854935,
      "grad_norm": 1.2582460641860962,
      "learning_rate": 0.00015734839476813314,
      "loss": 0.6757,
      "step": 4000
    },
    {
      "epoch": 2.3781212841854935,
      "eval_bleu": 71.81122168558296,
      "eval_loss": 0.5073844790458679,
      "eval_runtime": 93.6675,
      "eval_samples_per_second": 2.135,
      "eval_steps_per_second": 1.068,
      "step": 4000
    },
    {
      "epoch": 2.4078478002378123,
      "grad_norm": 1.6252491474151611,
      "learning_rate": 0.00015556480380499404,
      "loss": 0.6134,
      "step": 4050
    },
    {
      "epoch": 2.4375743162901307,
      "grad_norm": 1.3127505779266357,
      "learning_rate": 0.00015378121284185492,
      "loss": 0.6269,
      "step": 4100
    },
    {
      "epoch": 2.4673008323424495,
      "grad_norm": 1.2451525926589966,
      "learning_rate": 0.0001519976218787158,
      "loss": 0.6438,
      "step": 4150
    },
    {
      "epoch": 2.4970273483947683,
      "grad_norm": 1.3102949857711792,
      "learning_rate": 0.00015021403091557668,
      "loss": 0.6604,
      "step": 4200
    },
    {
      "epoch": 2.4970273483947683,
      "eval_bleu": 72.59867706190914,
      "eval_loss": 0.4926152527332306,
      "eval_runtime": 94.6215,
      "eval_samples_per_second": 2.114,
      "eval_steps_per_second": 1.057,
      "step": 4200
    },
    {
      "epoch": 2.5267538644470866,
      "grad_norm": 1.308616280555725,
      "learning_rate": 0.00014843043995243756,
      "loss": 0.6311,
      "step": 4250
    },
    {
      "epoch": 2.5564803804994054,
      "grad_norm": 1.0165988206863403,
      "learning_rate": 0.00014664684898929844,
      "loss": 0.6379,
      "step": 4300
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 1.3543332815170288,
      "learning_rate": 0.00014486325802615932,
      "loss": 0.5828,
      "step": 4350
    },
    {
      "epoch": 2.6159334126040426,
      "grad_norm": 1.2989792823791504,
      "learning_rate": 0.0001430796670630202,
      "loss": 0.6293,
      "step": 4400
    },
    {
      "epoch": 2.6159334126040426,
      "eval_bleu": 73.39877041105872,
      "eval_loss": 0.4704532325267792,
      "eval_runtime": 91.2008,
      "eval_samples_per_second": 2.193,
      "eval_steps_per_second": 1.096,
      "step": 4400
    },
    {
      "epoch": 2.6456599286563613,
      "grad_norm": 1.0545469522476196,
      "learning_rate": 0.00014129607609988107,
      "loss": 0.6077,
      "step": 4450
    },
    {
      "epoch": 2.67538644470868,
      "grad_norm": 1.285698413848877,
      "learning_rate": 0.00013951248513674198,
      "loss": 0.6066,
      "step": 4500
    },
    {
      "epoch": 2.705112960760999,
      "grad_norm": 1.305688738822937,
      "learning_rate": 0.00013772889417360283,
      "loss": 0.6046,
      "step": 4550
    },
    {
      "epoch": 2.7348394768133177,
      "grad_norm": 0.9924853444099426,
      "learning_rate": 0.00013594530321046374,
      "loss": 0.6432,
      "step": 4600
    },
    {
      "epoch": 2.7348394768133177,
      "eval_bleu": 74.10001872661043,
      "eval_loss": 0.4852162301540375,
      "eval_runtime": 88.6704,
      "eval_samples_per_second": 2.256,
      "eval_steps_per_second": 1.128,
      "step": 4600
    },
    {
      "epoch": 2.764565992865636,
      "grad_norm": 1.492263674736023,
      "learning_rate": 0.00013416171224732461,
      "loss": 0.6237,
      "step": 4650
    },
    {
      "epoch": 2.794292508917955,
      "grad_norm": 1.3345540761947632,
      "learning_rate": 0.00013237812128418547,
      "loss": 0.6158,
      "step": 4700
    },
    {
      "epoch": 2.8240190249702737,
      "grad_norm": 1.5188698768615723,
      "learning_rate": 0.00013059453032104637,
      "loss": 0.5979,
      "step": 4750
    },
    {
      "epoch": 2.853745541022592,
      "grad_norm": 1.2321375608444214,
      "learning_rate": 0.00012881093935790725,
      "loss": 0.6015,
      "step": 4800
    },
    {
      "epoch": 2.853745541022592,
      "eval_bleu": 74.3872498150946,
      "eval_loss": 0.45112091302871704,
      "eval_runtime": 90.3498,
      "eval_samples_per_second": 2.214,
      "eval_steps_per_second": 1.107,
      "step": 4800
    },
    {
      "epoch": 2.883472057074911,
      "grad_norm": 1.3991416692733765,
      "learning_rate": 0.00012702734839476813,
      "loss": 0.6117,
      "step": 4850
    },
    {
      "epoch": 2.9131985731272296,
      "grad_norm": 0.9464318156242371,
      "learning_rate": 0.000125243757431629,
      "loss": 0.6124,
      "step": 4900
    },
    {
      "epoch": 2.942925089179548,
      "grad_norm": 1.0552005767822266,
      "learning_rate": 0.00012346016646848989,
      "loss": 0.6328,
      "step": 4950
    },
    {
      "epoch": 2.972651605231867,
      "grad_norm": 1.6156961917877197,
      "learning_rate": 0.00012167657550535076,
      "loss": 0.5995,
      "step": 5000
    },
    {
      "epoch": 2.972651605231867,
      "eval_bleu": 74.65971716821818,
      "eval_loss": 0.4400728642940521,
      "eval_runtime": 92.0824,
      "eval_samples_per_second": 2.172,
      "eval_steps_per_second": 1.086,
      "step": 5000
    },
    {
      "epoch": 3.0023781212841856,
      "grad_norm": 1.4838545322418213,
      "learning_rate": 0.00011989298454221164,
      "loss": 0.6196,
      "step": 5050
    },
    {
      "epoch": 3.0321046373365044,
      "grad_norm": 1.506181240081787,
      "learning_rate": 0.00011810939357907251,
      "loss": 0.5528,
      "step": 5100
    },
    {
      "epoch": 3.0618311533888227,
      "grad_norm": 1.3283286094665527,
      "learning_rate": 0.0001163258026159334,
      "loss": 0.5646,
      "step": 5150
    },
    {
      "epoch": 3.0915576694411415,
      "grad_norm": 1.2427829504013062,
      "learning_rate": 0.00011454221165279429,
      "loss": 0.5799,
      "step": 5200
    },
    {
      "epoch": 3.0915576694411415,
      "eval_bleu": 75.5888902287065,
      "eval_loss": 0.4507509469985962,
      "eval_runtime": 90.6082,
      "eval_samples_per_second": 2.207,
      "eval_steps_per_second": 1.104,
      "step": 5200
    },
    {
      "epoch": 3.1212841854934603,
      "grad_norm": 1.4997155666351318,
      "learning_rate": 0.00011275862068965516,
      "loss": 0.5802,
      "step": 5250
    },
    {
      "epoch": 3.1510107015457787,
      "grad_norm": 0.9318199753761292,
      "learning_rate": 0.00011097502972651604,
      "loss": 0.5963,
      "step": 5300
    },
    {
      "epoch": 3.1807372175980975,
      "grad_norm": 1.2359883785247803,
      "learning_rate": 0.00010919143876337693,
      "loss": 0.554,
      "step": 5350
    },
    {
      "epoch": 3.2104637336504163,
      "grad_norm": 1.1791751384735107,
      "learning_rate": 0.00010740784780023779,
      "loss": 0.5504,
      "step": 5400
    },
    {
      "epoch": 3.2104637336504163,
      "eval_bleu": 75.03122596813274,
      "eval_loss": 0.45140331983566284,
      "eval_runtime": 94.9638,
      "eval_samples_per_second": 2.106,
      "eval_steps_per_second": 1.053,
      "step": 5400
    },
    {
      "epoch": 3.240190249702735,
      "grad_norm": 1.360667109489441,
      "learning_rate": 0.00010562425683709868,
      "loss": 0.5467,
      "step": 5450
    },
    {
      "epoch": 3.2699167657550534,
      "grad_norm": 0.8416523933410645,
      "learning_rate": 0.00010384066587395956,
      "loss": 0.5807,
      "step": 5500
    },
    {
      "epoch": 3.299643281807372,
      "grad_norm": 1.4980801343917847,
      "learning_rate": 0.00010205707491082044,
      "loss": 0.5898,
      "step": 5550
    },
    {
      "epoch": 3.329369797859691,
      "grad_norm": 1.0998209714889526,
      "learning_rate": 0.00010027348394768132,
      "loss": 0.5622,
      "step": 5600
    },
    {
      "epoch": 3.329369797859691,
      "eval_bleu": 75.28572320411295,
      "eval_loss": 0.4563032388687134,
      "eval_runtime": 93.3488,
      "eval_samples_per_second": 2.143,
      "eval_steps_per_second": 1.071,
      "step": 5600
    },
    {
      "epoch": 3.3590963139120094,
      "grad_norm": 1.4240339994430542,
      "learning_rate": 9.848989298454221e-05,
      "loss": 0.5671,
      "step": 5650
    },
    {
      "epoch": 3.388822829964328,
      "grad_norm": 1.355873942375183,
      "learning_rate": 9.670630202140308e-05,
      "loss": 0.5649,
      "step": 5700
    },
    {
      "epoch": 3.418549346016647,
      "grad_norm": 1.2803406715393066,
      "learning_rate": 9.492271105826396e-05,
      "loss": 0.5769,
      "step": 5750
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.9625328183174133,
      "learning_rate": 9.313912009512485e-05,
      "loss": 0.5362,
      "step": 5800
    },
    {
      "epoch": 3.4482758620689653,
      "eval_bleu": 75.29226840914404,
      "eval_loss": 0.44783031940460205,
      "eval_runtime": 86.0838,
      "eval_samples_per_second": 2.323,
      "eval_steps_per_second": 1.162,
      "step": 5800
    }
  ],
  "logging_steps": 50,
  "max_steps": 8410,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.162175995628749e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
