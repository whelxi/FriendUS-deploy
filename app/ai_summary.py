import json
import re
from typing import List, Dict
from openai import OpenAI
from config import Config


class SeaLionDialogueSystem:
    def __init__(self):
        # Gi·ªØ nguy√™n c√°ch kh·ªüi t·∫°o b·∫£o m·∫≠t t·ª´ file new
        self.client = OpenAI(
            api_key=Config.SEALION_API_KEY,
            base_url=Config.SEALION_BASE_URL
        )
        self.model_name = "aisingapore/Gemma-SEA-LION-v4-27B-IT"

    def _call_model(self, prompt: str, system_prompt: str) -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,  # Gi·∫£m nhi·ªát ƒë·ªô ƒë·ªÉ Output ·ªïn ƒë·ªãnh h∆°n (ƒë·∫∑c bi·ªát l√† JSON)
                max_tokens=2048
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"L·ªói API SeaLion: {e}"

    def _clean_json_output(self, raw_string: str):
        """H√†m ph·ª• tr·ª£ ƒë·ªÉ l√†m s·∫°ch chu·ªói JSON do AI sinh ra (x·ª≠ l√Ω Markdown)"""
        try:
            # X√≥a c√°c k√Ω t·ª± markdown nh∆∞ ```json ho·∫∑c ```
            clean_str = re.sub(r"```json|```", "", raw_string).strip()
            return clean_str
        except:
            return raw_string

    # --- STAGE 1: COREFERENCE & NORMALIZATION (Theo ai_summary.py) ---
    def stage_1_cleansing(self, chat_history: List[Dict]) -> str:
        # Chuy·ªÉn ƒë·ªïi List[Dict] th√†nh chu·ªói h·ªôi tho·∫°i th√¥
        chat_str = "\n".join([f"{msg['speaker']}: {msg['text']}" for msg in chat_history])

        sys_prompt = """Nhi·ªám v·ª•: Gi·∫£i quy·∫øt Coreference v√† Chu·∫©n h√≥a vƒÉn b·∫£n.
1. Thay th·∫ø t·∫•t c·∫£ ƒë·∫°i t·ª´ (n√≥, h·ªç, m, t, h·∫Øn...) b·∫±ng danh t·ª´/t√™n ri√™ng t∆∞∆°ng ·ª©ng trong ng·ªØ c·∫£nh.
2. Chuy·ªÉn teencode/vi·∫øt t·∫Øt th√†nh ti·∫øng Vi·ªát chu·∫©n.
ƒê·∫¶U RA: Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung chat ƒë√£ l√†m s·∫°ch, ƒë·ªãnh d·∫°ng 'T√™n: N·ªôi dung'."""

        return self._call_model(chat_str, sys_prompt)

    # --- STAGE 2: DIALOGUE ACT TAGGING (Theo ai_summary.py) ---
    def stage_2_tagging(self, clean_chat: str) -> str:
        sys_prompt = """ƒê√≥ng vai tr√≤ l√† c√¥ng c·ª• Chat Corpora Annotator (CCA). 
G√°n nh√£n 'Dialogue Act' cho t·ª´ng c√¢u tho·∫°i ƒë·ªÉ x√¢y d·ª±ng c·∫•u tr√∫c tƒ©nh (Static Structure):
- REQUEST: ƒê∆∞a ra ƒë·ªÅ xu·∫•t/c√¢u h·ªèi.
- INFORM: Cung c·∫•p s·ª± th·∫≠t/th√¥ng tin.
- ADVISE: ƒê∆∞a ra l·ªùi khuy√™n/√Ω ki·∫øn.
- RESPOND: Ph·∫£n h·ªìi ƒë·ªìng √Ω (ACCEPT) ho·∫∑c t·ª´ ch·ªëi (REJECT).
- RESOLVE: Ch·ªët h·∫° v·∫•n ƒë·ªÅ.

ƒê·∫¶U RA JSON duy nh·∫•t: [{"s": "T√™n ng∆∞·ªùi", "a": "Nh√£n h√†nh ƒë·ªông", "t": "N·ªôi dung"}]"""

        result = self._call_model(clean_chat, sys_prompt)
        return self._clean_json_output(result)

    # --- STAGE 3: DYNAMIC SEGMENTATION (Theo ai_summary.py) ---
    def stage_3_segmentation(self, tagged_json: str) -> str:
        sys_prompt = """D·ª±a tr√™n c√°c nh√£n Dialogue Act, h√£y th·ª±c hi·ªán Dynamic Topic Segmentation.
Gom nh√≥m c√°c c√¢u tho·∫°i li√™n quan th√†nh c√°c 'S·ª± vi·ªác' (Events).
V·ªõi m·ªói s·ª± vi·ªác, x√°c ƒë·ªãnh:
1. Topic: T√™n v·ª• vi·ªác.
2. Initiator: Ng∆∞·ªùi kh∆°i m√†o.
3. Interaction Flow: Lu·ªìng th·∫£o lu·∫≠n (Ai ph·∫£n ƒë·ªëi ai, ai cung c·∫•p th√™m tin).
4. Status: K·∫øt qu·∫£ cu·ªëi c√πng (ƒê√£ ch·ªët/Ch∆∞a ch·ªët).

ƒê·∫¶U RA JSON: {"events": [{"topic": "...", "flow": "...", "status": "..."}]}"""

        result = self._call_model(tagged_json, sys_prompt)
        return self._clean_json_output(result)

    # --- STAGE 4: ABSTRACTIVE SUMMARY GENERATION (Theo ai_summary.py) ---
    def stage_4_summarization(self, segments_json: str) -> str:
        sys_prompt = """B·∫°n l√† m·ªôt th√†nh vi√™n trong nh√≥m, t√≥m t·∫Øt l·∫°i n·ªôi dung bu·ªïi tr√≤ chuy·ªán h√¥m nay cho nh·ªØng ng∆∞·ªùi 'l·∫∑n' l√¢u kh√¥ng ƒë·ªçc tin nh·∫Øn.
VƒÉn phong: Th√¢n thi·ªán, h√†i h∆∞·ªõc, s·ª≠ d·ª•ng ng√¥n ng·ªØ c·ªßa gi·ªõi tr·∫ª (nh∆∞ng v·∫´n d·ªÖ hi·ªÉu). C√≥ th·ªÉ d√πng emoji ph√π h·ª£p.

C·∫§U TR√öC B√ÅO C√ÅO:
üî• C√ì G√å HOT: (T√≥m t·∫Øt nhanh nh·ªØng drama ho·∫∑c s·ª± ki·ªán n·ªïi b·∫≠t nh·∫•t)
üí¨ CHI TI·∫æT C√ÅC K√àO: 
   - [T√™n k√®o/v·ª•]: K·ªÉ l·∫°i ng·∫Øn g·ªçn ai ƒë√£ n√≥i g√¨, ch·ªët h·∫° ra sao. 
‚úÖ VI·ªÜC C·∫¶N L√ÄM: (Li·ªát k√™ danh s√°ch ai c·∫ßn l√†m g√¨, v√≠ d·ª•: 'Th·∫±ng Nam nh·ªõ mang ti·ªÅn', 'T·ªëi nay 7h t·∫≠p trung'...)"""

        return self._call_model(segments_json, sys_prompt)

    # --- MAIN PROCESS (PAPER PIPELINE) ---
    def process(self, raw_chat: List[Dict]):
        # Pipeline th·ª±c thi tu·∫ßn t·ª± 4 b∆∞·ªõc theo paper
        s1_clean = self.stage_1_cleansing(raw_chat)
        s2_tagged = self.stage_2_tagging(s1_clean)
        s3_segments = self.stage_3_segmentation(s2_tagged)
        s4_final = self.stage_4_summarization(s3_segments)
        return s4_final

    # --- SIMPLE PROCESS (Gi·ªØ l·∫°i t·ª´ file new) ---
    def simple_process(self, raw_chat: List[Dict]) -> str:
        chat_str = "\n".join([f"{msg['speaker']}: {msg['text']}" for msg in raw_chat])
        sys_prompt = """
B·∫°n l√† tr·ª£ l√Ω ·∫£o t·ªïng h·ª£p tin nh·∫Øn nh√≥m.
Nhi·ªám v·ª•: ƒê·ªçc ƒëo·∫°n h·ªôi tho·∫°i v√† t√≥m t·∫Øt l·∫°i 3 √Ω ch√≠nh quan tr·ªçng nh·∫•t m·ªôt c√°ch ng·∫Øn g·ªçn, s√∫c t√≠ch.
Kh√¥ng c·∫ßn ph√¢n t√≠ch s√¢u, ch·ªâ c·∫ßn n·∫Øm b·∫Øt th√¥ng tin b·ªÅ m·∫∑t nhanh ch√≥ng."""

        return self._call_model(f"H·ªôi tho·∫°i:\n{chat_str}", sys_prompt)