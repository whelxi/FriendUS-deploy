import json
from typing import List, Dict
from openai import OpenAI
from config import Config

class SeaLionDialogueSystem:
    def __init__(self):
        # L·∫•y Key t·ª´ Config b·∫£o m·∫≠t
        self.client = OpenAI(
            api_key=Config.SEALION_API_KEY, 
            base_url=Config.SEALION_BASE_URL
        )
        self.model_name = "aisingapore/Gemma-SEA-LION-v4-27B-IT"

    def _call_model(self, prompt: str, system_prompt: str) -> str:
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=2048
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"L·ªói API SeaLion: {e}"

    # --- B∆Ø·ªöC 1: CHU·∫®N H√ìA (TEENCODE/SLANG) ---
    def normalize_text(self, chat_history: List[Dict]) -> List[Dict]:
        chat_str = "\n".join([f"{i}|{msg['speaker']}: {msg['text']}" for i, msg in enumerate(chat_history)])
        sys_prompt = """
B·∫°n l√† m·ªôt chuy√™n gia ng√¥n ng·ªØ h·ªçc v·ªÅ ti·∫øng l√≥ng v√† vƒÉn h√≥a m·∫°ng Vi·ªát Nam. 
Nhi·ªám v·ª•: Chuy·ªÉn ƒë·ªïi ƒëo·∫°n h·ªôi tho·∫°i sau sang ti·∫øng Vi·ªát chu·∫©n m·ª±c.

C√ÅC R√ÄNG BU·ªòC NGHI√äM NG·∫∂T:
1. KH√îNG ƒê∆Ø·ª¢C B·ªé S√ìT b·∫•t k·ª≥ t·ª´ teencode n√†o (vd: j, k, ko, ƒëc, s, vcl, clgt, b√≠t, m, t...).
2. GI·ªÆ NGUY√äN c·∫•u tr√∫c ID|Speaker: Text.
3. N·∫øu g·∫∑p t·ª´ kh√¥ng hi·ªÉu, h√£y gi·ªØ nguy√™n nh∆∞ng c·ªë g·∫Øng ƒëo√°n d·ª±a tr√™n ng·ªØ c·∫£nh xung quanh.
4. ƒê·∫£m b·∫£o s·ªë d√≤ng ƒë·∫ßu ra b·∫±ng ch√≠nh x√°c s·ªë d√≤ng ƒë·∫ßu v√†o.

INPUT FORMAT: ID|Speaker: Text"""

        result = self._call_model(f"D·ªØ li·ªáu:\n{chat_str}", sys_prompt)
        
        normalized_chat = []
        for line in result.split('\n'):
            if "|" in line and ":" in line:
                try:
                    parts = line.split("|")
                    idx = int(parts[0])
                    text = line.split(":", 1)[1].strip()
                    msg = chat_history[idx].copy()
                    msg['norm_text'] = text
                    normalized_chat.append(msg)
                except:
                    continue
        return normalized_chat if normalized_chat else chat_history

    # --- B∆Ø·ªöC 2: GI·∫¢I QUY·∫æT ƒê·ªíNG THAM CHI·∫æU (COREFERENCE) ---
    def coreference_resolution(self, chat_history: List[Dict]) -> List[Dict]:
        chat_str = "\n".join(
            [f"{i}|{msg['speaker']}: {msg.get('norm_text', msg['text'])}" for i, msg in enumerate(chat_history)])
        sys_prompt = """
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ng·ªØ c·∫£nh h·ªôi tho·∫°i (Coreference Resolution).
Nhi·ªám v·ª•: Thay th·∫ø T·∫§T C·∫¢ c√°c ƒë·∫°i t·ª´ nh√¢n x∆∞ng m∆° h·ªì b·∫±ng t√™n ri√™ng c·ªßa th·ª±c th·ªÉ m√† ch√∫ng √°m ch·ªâ.

DANH S√ÅCH KI·ªÇM TRA (CHECKLIST):
- 'n√≥', 'h·∫Øn', '·ªïng', 'b·∫£', 'em n√≥' -> Thay b·∫±ng t√™n ng∆∞·ªùi c·ª• th·ªÉ.
- 'ƒë√≥', 'kia', '·∫•y' (khi ch·ªâ s·ª± v·∫≠t/s·ª± vi·ªác ƒë√£ n√≥i ·ªü tr√™n) -> Thay b·∫±ng t√™n s·ª± vi·ªác c·ª• th·ªÉ.
- V√≠ d·ª•: "B√¨nh: N√≥ kh√¥ng cho m∆∞·ª£n" -> "B√¨nh: Minh kh√¥ng cho m∆∞·ª£n" (n·∫øu ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥ l√† Minh).

Y√äU C·∫¶U: Ph·∫£i r√† so√°t t·ª´ng c√¢u m·ªôt. N·∫øu c√¢u n√†o kh√¥ng c√≥ ƒë·∫°i t·ª´, gi·ªØ nguy√™n. 
TR·∫¢ V·ªÄ ƒê·ªäNH D·∫†NG: ID|Text ƒë√£ thay th·∫ø."""

        result = self._call_model(f"ƒêo·∫°n chat:\n{chat_str}", sys_prompt)
        
        for line in result.split('\n'):
            if "|" in line:
                try:
                    parts = line.split("|")
                    idx = int(parts[0])
                    resolved_text = parts[1].strip()
                    chat_history[idx]['coref_text'] = resolved_text
                except:
                    continue
        return chat_history

    # --- B∆Ø·ªöC 3: PH√ÇN ƒêO·∫†N CH·ª¶ ƒê·ªÄ (TOPIC SEGMENTATION) ---
    def dynamic_topic_segmentation(self, chat_history: List[Dict]) -> str:
        chat_content = "\n".join(
            [f"{msg['speaker']}: {msg.get('coref_text', msg.get('norm_text'))}" for msg in chat_history])
        sys_prompt = """
B·∫°n l√† m·ªôt ng∆∞·ªùi chuy√™n ƒëi 'h√≥ng h·ªõt' v√† k·ªÉ l·∫°i chuy·ªán trong group chat cho b·∫°n b√®. 
H√£y ƒë·ªçc ƒëo·∫°n chat v√† chia nh·ªè xem h·ªôi tho·∫°i n√†y g·ªìm nh·ªØng 'k√®o' n√†o ho·∫∑c nh·ªØng 'v·ª•' n√†o ƒëang hot.

Y√äU C·∫¶U JSON:
{
  "segments": [
    {
      "topic_name": "T√™n v·ª• vi·ªác (v√≠ d·ª•: K√®o ƒëi nh·∫≠u, Drama th·∫±ng Nam...)",
      "whats_happening": "Chuy·ªán g√¨ ƒëang x·∫£y ra v·∫≠y? (K·ªÉ l·∫°i ki·ªÉu th√¢n thi·ªán)",
      "main_characters": ["Nh·ªØng ai tham gia v·ª• n√†y"]
    }
  ]
}"""
        result = self._call_model(chat_content, sys_prompt)
        return result

    # --- B∆Ø·ªöC 4: T·ªîNG H·ª¢P ---
    def process(self, raw_chat: List[Dict]):
        # Pipeline x·ª≠ l√Ω
        chat_norm = self.normalize_text(raw_chat)
        chat_coref = self.coreference_resolution(chat_norm)
        topics_json = self.dynamic_topic_segmentation(chat_coref)

        sys_prompt = """
B·∫°n l√† m·ªôt th√†nh vi√™n trong nh√≥m, t√≥m t·∫Øt l·∫°i n·ªôi dung bu·ªïi tr√≤ chuy·ªán h√¥m nay cho nh·ªØng ng∆∞·ªùi 'l·∫∑n' l√¢u kh√¥ng ƒë·ªçc tin nh·∫Øn.
VƒÉn phong: Th√¢n thi·ªán, h√†i h∆∞·ªõc, s·ª≠ d·ª•ng ng√¥n ng·ªØ c·ªßa gi·ªõi tr·∫ª (nh∆∞ng v·∫´n d·ªÖ hi·ªÉu). C√≥ th·ªÉ d√πng emoji ph√π h·ª£p.

C·∫§U TR√öC B√ÅO C√ÅO:
üî• C√ì G√å HOT: (T√≥m t·∫Øt nhanh nh·ªØng drama ho·∫∑c s·ª± ki·ªán n·ªïi b·∫≠t nh·∫•t)
üí¨ CHI TI·∫æT C√ÅC K√àO: 
   - [T√™n k√®o/v·ª•]: K·ªÉ l·∫°i ng·∫Øn g·ªçn ai ƒë√£ n√≥i g√¨, ch·ªët h·∫° ra sao. 
‚úÖ VI·ªÜC C·∫¶N L√ÄM: (Li·ªát k√™ danh s√°ch ai c·∫ßn l√†m g√¨, v√≠ d·ª•: 'Th·∫±ng Nam nh·ªõ mang ti·ªÅn', 'T·ªëi nay 7h t·∫≠p trung'...)"""
        
        final_summary = self._call_model(f"D·ªØ li·ªáu:\n{topics_json}", sys_prompt)
        return final_summary